# DOSSIER TECHNIQUE COMPLET ‚Äî Classification des Iris
# Fichier de r√©f√©rence pour la r√©daction du rapport Word

> Ce document contient TOUTES les donn√©es techniques, chiffres, r√©sultats, structures et analyses
> n√©cessaires pour r√©diger un rapport complet r√©pondant aux exigences des deux briefs :
> - `Aide projet ‚Äì Classification des iris.md`
> - `ListeProjet.md` (Projet 1)

---

## üìÅ CONTEXTE DU PROJET

**Titre** : Classification d'esp√®ces de fleurs avec MongoDB et optimisation des performances

**Probl√©matique m√©tier** : Une application scientifique collecte des mesures morphologiques de fleurs. L'objectif est de pr√©dire automatiquement l'esp√®ce parmi Setosa, Versicolor et Virginica.

**Dataset** : UCI Machine Learning Repository ‚Äî Iris Dataset (Ronald Fisher, 1936)
- 150 observations
- 4 variables num√©riques + 1 variable cible (esp√®ce)
- Aucune valeur manquante
- Dataset parfaitement √©quilibr√© : 50 observations par esp√®ce

**Architecture technique** :
- **MongoDB** : Stockage principal des donn√©es et des pr√©dictions (document store)
- **Cassandra** : Stockage historique avec partitionnement par esp√®ce (wide-column store)
- **Redis** : Cache temps r√©el pour les pr√©dictions du dashboard (<1ms)
- **Apache Spark MLlib** : Entra√Ænement distribu√© des mod√®les de classification
- **Streamlit** : Dashboard interactif
- **Python** : Langage principal (pandas, scikit-learn, statsmodels, seaborn, matplotlib)

**Stack technique compl√®te** :
- Python 3.13
- PySpark 3.5.1
- MongoDB Spark Connector 10.3.0
- pymongo, cassandra-driver, redis
- statsmodels (r√©gressions OLS)
- scikit-learn (m√©triques, rapports de classification)
- Streamlit (dashboard)
- Docker (MongoDB, Cassandra, Redis)

---

## üìä PARTIE 1 ‚Äî ANALYSE STATISTIQUE DESCRIPTIVE

### 1.1 Exploration du dataset

| Caract√©ristique | Valeur |
|---|---|
| Nombre d'observations | 150 |
| Nombre de variables | 5 (4 num√©riques + 1 cat√©gorielle) |
| Types de variables | float64 (√ó4), object (√ó1) |
| Valeurs manquantes | 0 (aucune) |
| Classes | 3 esp√®ces (Iris-setosa, Iris-versicolor, Iris-virginica) |

### 1.2 Statistiques descriptives globales

| Statistique | sepal_length | sepal_width | petal_length | petal_width |
|---|---|---|---|---|
| **count** | 150 | 150 | 150 | 150 |
| **mean** | 5.843 | 3.057 | 3.758 | 1.199 |
| **std** | 0.828 | 0.436 | 1.765 | 0.762 |
| **min** | 4.300 | 2.000 | 1.000 | 0.100 |
| **25%** | 5.100 | 2.800 | 1.600 | 0.300 |
| **50% (m√©diane)** | 5.800 | 3.000 | 4.350 | 1.300 |
| **75%** | 6.400 | 3.300 | 5.100 | 1.800 |
| **max** | 7.900 | 4.400 | 6.900 | 2.500 |

### 1.3 Comptage par esp√®ce

| Esp√®ce | Nombre |
|---|---|
| Iris-setosa | 50 |
| Iris-versicolor | 50 |
| Iris-virginica | 50 |

**Conclusion** : Le dataset est **parfaitement √©quilibr√©** avec exactement 50 observations par esp√®ce. Aucune esp√®ce n'est surrepr√©sent√©e.

### 1.4 Moyennes par esp√®ce

| Esp√®ce | sepal_length | sepal_width | petal_length | petal_width |
|---|---|---|---|---|
| Iris-setosa | 5.006 | 3.418 | 1.464 | 0.244 |
| Iris-versicolor | 5.936 | 2.770 | 4.260 | 1.326 |
| Iris-virginica | 6.588 | 2.974 | 5.552 | 2.026 |

### 1.5 Variance par esp√®ce

| Esp√®ce | sepal_length | sepal_width | petal_length | petal_width |
|---|---|---|---|---|
| Iris-setosa | 0.124 | 0.145 | 0.030 | 0.011 |
| Iris-versicolor | 0.266 | 0.098 | 0.221 | 0.039 |
| Iris-virginica | 0.404 | 0.104 | 0.305 | 0.075 |

**Analyse de la variance** :
- Iris-setosa a la variance la plus faible sur les p√©tales ‚Üí esp√®ce tr√®s homog√®ne
- Iris-virginica a la variance la plus √©lev√©e ‚Üí esp√®ce avec plus de variabilit√© morphologique
- Les p√©tales (longueur et largeur) montrent les √©carts inter-esp√®ces les plus marqu√©s

### 1.6 Variables discriminantes

**Les p√©tales sont nettement plus discriminants que les s√©pales**, car :
1. L'√©cart de petal_length entre Setosa (1.464 cm) et Virginica (5.552 cm) est de **4.088 cm** (√ó3.8)
2. L'√©cart de petal_width entre Setosa (0.244 cm) et Virginica (2.026 cm) est de **1.782 cm** (√ó8.3)
3. L'√©cart de sepal_length n'est que de 1.582 cm (√ó1.3) ‚Äî beaucoup moins discriminant
4. sepal_width est la variable la MOINS discriminante (variance inter-esp√®ces faible)

---

## üìä PARTIE 2 ‚Äî VISUALISATION DES DONN√âES

### 2.1 Graphiques g√©n√©r√©s

| Graphique | Fichier | Description |
|---|---|---|
| Pairplot | `output/plots/pairplot.png` | Scatter plots de toutes les combinaisons de variables, color√©es par esp√®ce |
| Matrice de corr√©lation | `output/plots/correlation_matrix.png` | Heatmap des corr√©lations entre variables num√©riques |
| Boxplots | `output/plots/boxplots.png` | Distribution de chaque variable (min, Q1, m√©diane, Q3, max) |
| Violin sepal_length | `output/plots/violin_sepal_length.png` | Distribution de sepal_length par esp√®ce |
| Violin sepal_width | `output/plots/violin_sepal_width.png` | Distribution de sepal_width par esp√®ce |
| Violin petal_length | `output/plots/violin_petal_length.png` | Distribution de petal_length par esp√®ce |
| Violin petal_width | `output/plots/violin_petal_width.png` | Distribution de petal_width par esp√®ce |

### 2.2 Matrice de corr√©lation (chiffres)

|  | sepal_length | sepal_width | petal_length | petal_width |
|---|---|---|---|---|
| **sepal_length** | 1.000 | -0.109 | **0.872** | **0.818** |
| **sepal_width** | -0.109 | 1.000 | -0.421 | -0.357 |
| **petal_length** | **0.872** | -0.421 | 1.000 | **0.963** |
| **petal_width** | **0.818** | -0.357 | **0.963** | 1.000 |

**Corr√©lations cl√©s** :
- **petal_length ‚Üî petal_width** : r = 0.963 ‚Üí Corr√©lation **tr√®s forte** (quasi parfaite)
- **sepal_length ‚Üî petal_length** : r = 0.872 ‚Üí Corr√©lation **forte**
- **sepal_length ‚Üî petal_width** : r = 0.818 ‚Üí Corr√©lation **forte**
- **sepal_width ‚Üî sepal_length** : r = -0.109 ‚Üí Corr√©lation **quasi-nulle** (aucun lien lin√©aire)
- **sepal_width** est **n√©gativement** corr√©l√©e aux dimensions des p√©tales (-0.42 et -0.36)

**Observations visuelles cl√©s** (pairplot) :
- Iris-setosa forme un **cluster clairement s√©par√©** dans toutes les projections impliquant les p√©tales
- Iris-versicolor et Iris-virginica se **chevauchent partiellement** sur les dimensions des s√©pales
- Les dimensions des p√©tales permettent une **s√©paration quasi-parfaite** entre les 3 esp√®ces

---

## üìà PARTIE 3 ‚Äî R√âGRESSION SIMPLE ET MULTIPLE

### 3.1 R√©gression Lin√©aire Simple : petal_length ~ sepal_length

```
                            OLS Regression Results
==============================================================================
Dep. Variable:           petal_length   R-squared:                       0.760
Model:                            OLS   Adj. R-squared:                  0.758
Method:                 Least Squares   F-statistic:                     468.6
                                        Prob (F-statistic):           1.04e-47
No. Observations:                 150
==============================================================================
                   coef    std err          t      P>|t|      [0.025      0.975]
--------------------------------------------------------------------------------
const           -7.1014      0.507    -14.016      0.000      -8.103      -6.100
sepal_length     1.8584      0.086     21.646      0.000       1.689       2.028
==============================================================================
Omnibus:                        0.253   Durbin-Watson:                   1.204
Prob(Omnibus):                  0.881   Jarque-Bera (JB):                0.386
Skew:                          -0.082   Prob(JB):                        0.824
Kurtosis:                       2.812   Cond. No.                         43.4
==============================================================================
```

**Interpr√©tation R√©gression Simple** :
- **R¬≤ = 0.760** : Le mod√®le explique **76% de la variance** de petal_length
- **Coefficient sepal_length = 1.858** : Pour chaque cm de sepal_length en plus, petal_length augmente de 1.858 cm
- **p-value < 0.001** : La relation est **hautement significative**
- **F-statistic = 468.6** : Le mod√®le global est tr√®s significatif
- **Normalit√© des r√©sidus** : Prob(Omnibus) = 0.881, Prob(JB) = 0.824 ‚Üí Les r√©sidus sont **normaux** (hypoth√®se respect√©e)
- **Durbin-Watson = 1.204** : L√©g√®re auto-corr√©lation positive (valeur id√©ale = 2.0)
- Le graphique est disponible dans `output/regression/regression_simple_plot.png`

### 3.2 R√©gression Lin√©aire Multiple : petal_length ~ sepal_length + sepal_width + petal_width

```
                            OLS Regression Results
==============================================================================
Dep. Variable:           petal_length   R-squared:                       0.968
Model:                            OLS   Adj. R-squared:                  0.967
Method:                 Least Squares   F-statistic:                     1473.
                                        Prob (F-statistic):          6.98e-109
No. Observations:                 150
==============================================================================
                   coef    std err          t      P>|t|      [0.025      0.975]
--------------------------------------------------------------------------------
const           -0.2627      0.297     -0.883      0.379      -0.850       0.325
sepal_length     0.7291      0.058     12.502      0.000       0.614       0.844
sepal_width     -0.6460      0.068     -9.431      0.000      -0.781      -0.511
petal_width      1.4468      0.068     21.399      0.000       1.313       1.580
==============================================================================
Omnibus:                        2.520   Durbin-Watson:                   1.783
Prob(Omnibus):                  0.284   Jarque-Bera (JB):                2.391
Skew:                           0.073   Prob(JB):                        0.303
Kurtosis:                       3.601   Cond. No.                         79.3
==============================================================================
```

**Interpr√©tation R√©gression Multiple** :
- **R¬≤ = 0.968** : Le mod√®le explique **96.8% de la variance** ‚Üí am√©lioration massive (+20.8 points vs simple)
- **Coefficients significatifs** :
  - `petal_width = 1.447` (t=21.4, p<0.001) : Variable la **plus influente** sur petal_length
  - `sepal_length = 0.729` (t=12.5, p<0.001) : Relation positive significative
  - `sepal_width = -0.646` (t=-9.4, p<0.001) : Relation **n√©gative** significative (√† s√©pales plus larges, p√©tales plus courts)
  - `const = -0.263` (p=0.379) : L'intercept n'est **pas significatif** ‚Üí le mod√®le passe par l'origine
- **Normalit√© des r√©sidus** : Prob(Omnibus) = 0.284, Prob(JB) = 0.303 ‚Üí R√©sidus normaux ‚úì
- **Durbin-Watson = 1.783** : Pas d'autocorr√©lation probl√©matique ‚úì
- Les graphiques de r√©sidus et QQ-plot sont dans `output/regression/residuals_plot.png` et `output/regression/residuals_qqplot.png`

### 3.3 Comparaison Simple vs Multiple

| M√©trique | R√©gression Simple | R√©gression Multiple |
|---|---|---|
| R¬≤ | 0.760 | **0.968** |
| R¬≤ ajust√© | 0.758 | **0.967** |
| F-statistic | 468.6 | **1473** |
| AIC | 385.1 | **86.82** |
| BIC | 391.2 | **98.86** |

**Conclusion** : Le mod√®le multiple am√©liore **consid√©rablement** la pr√©diction. L'AIC passe de 385 √† 87 (le plus bas est meilleur). La variable `petal_width` est le facteur le plus influent.

### 3.4 V√©rification des hypoth√®ses de r√©gression

| Hypoth√®se | V√©rification | R√©sultat |
|---|---|---|
| **Lin√©arit√©** | Scatter plot + R¬≤ √©lev√© | ‚úÖ Respect√©e |
| **Normalit√© des r√©sidus** | Prob(JB)=0.303, Prob(Omnibus)=0.284, QQ-plot | ‚úÖ Respect√©e |
| **Homosc√©dasticit√©** | Graphique r√©sidus vs pr√©dictions | ‚úÖ Respect√©e (dispersion uniforme) |
| **Absence d'autocorr√©lation** | Durbin-Watson = 1.783 | ‚úÖ Respect√©e |

Graphiques disponibles :
- `output/regression/residuals_plot.png` : Graphique des r√©sidus (homosc√©dasticit√©)
- `output/regression/residuals_qqplot.png` : QQ-plot (normalit√© des r√©sidus)

---

## üîÆ PARTIE 4 ‚Äî CLASSIFICATION SUPERVIS√âE

### 4.1 Configuration

- **Framework** : Apache Spark MLlib (traitement distribu√©)
- **Variables explicatives** : sepal_length, sepal_width, petal_length, petal_width
- **Variable cible** : label (esp√®ce) ‚Üí index√©e en labelIndex
- **Split** : 80% train / 20% test (seed=42)
- **Mod√®les test√©s** : Random Forest, Decision Tree, Logistic Regression

### 4.2 R√©sultats de classification

| Mod√®le | Accuracy | Precision | Recall | F1-Score |
|---|---|---|---|---|
| Random Forest | 91.67% | 91.67% | 91.67% | 91.67% |
| Decision Tree | 91.67% | 91.67% | 91.67% | 91.67% |
| **Logistic Regression** | **100.00%** | **100.00%** | **100.00%** | **100.00%** |

**Meilleur mod√®le** : Logistic Regression (100% sur le jeu de test)

### 4.3 Matrices de confusion

#### Random Forest
|  | Pr√©dit Setosa (0) | Pr√©dit Versicolor (1) | Pr√©dit Virginica (2) |
|---|---|---|---|
| **R√©el Setosa** | **12** | 0 | 0 |
| **R√©el Versicolor** | 0 | **4** | 1 |
| **R√©el Virginica** | 0 | 1 | **6** |

- Setosa : class√© parfaitement (12/12)
- Versicolor : 1 erreur ‚Üí confondu avec Virginica
- Virginica : 1 erreur ‚Üí confondu avec Versicolor
- Total : 22/24 = 91.67%

#### Decision Tree
|  | Pr√©dit Setosa (0) | Pr√©dit Versicolor (1) | Pr√©dit Virginica (2) |
|---|---|---|---|
| **R√©el Setosa** | **12** | 0 | 0 |
| **R√©el Versicolor** | 0 | **4** | 1 |
| **R√©el Virginica** | 0 | 1 | **6** |

- M√™me profil d'erreur que Random Forest

#### Logistic Regression (Meilleur mod√®le)
|  | Pr√©dit Setosa (0) | Pr√©dit Versicolor (1) | Pr√©dit Virginica (2) |
|---|---|---|---|
| **R√©el Setosa** | **12** | 0 | 0 |
| **R√©el Versicolor** | 0 | **5** | 0 |
| **R√©el Virginica** | 0 | 0 | **7** |

- **Classification parfaite** : aucune erreur (24/24)

### 4.4 Rapports de classification d√©taill√©s (par classe)

#### Random Forest / Decision Tree (m√™me profil)
| Classe | Precision | Recall | F1-Score | Support |
|---|---|---|---|---|
| Class_0 (Setosa) | 1.000 | 1.000 | 1.000 | 12 |
| Class_1 (Versicolor) | 0.800 | 0.800 | 0.800 | 5 |
| Class_2 (Virginica) | 0.857 | 0.857 | 0.857 | 7 |
| **weighted avg** | **0.917** | **0.917** | **0.917** | 24 |

#### Logistic Regression
| Classe | Precision | Recall | F1-Score | Support |
|---|---|---|---|---|
| Class_0 (Setosa) | 1.000 | 1.000 | 1.000 | 12 |
| Class_1 (Versicolor) | 1.000 | 1.000 | 1.000 | 5 |
| Class_2 (Virginica) | 1.000 | 1.000 | 1.000 | 7 |
| **weighted avg** | **1.000** | **1.000** | **1.000** | 24 |

### 4.5 Analyse des erreurs de classification

**Quelles esp√®ces sont les plus difficiles √† pr√©dire ?**
- **Iris-setosa** est toujours class√© **parfaitement** (100%) par tous les mod√®les ‚Üí esp√®ce morphologiquement tr√®s distincte (p√©tales beaucoup plus petits)
- **Iris-versicolor** et **Iris-virginica** sont les **plus confondues** entre elles ‚Üí elles ont des dimensions de p√©tales proches (overlap visible dans le pairplot)
- La confusion Versicolor ‚Üî Virginica s'explique par des dimensions de p√©tales qui se chevauchent partiellement (Versicolor : 4.26 cm petal_length vs Virginica : 5.55 cm)

**Pourquoi la Logistic Regression surpasse les arbres ?**
- Les fronti√®res de d√©cision entre esp√®ces sont **lin√©airement s√©parables** dans cet espace √† 4 dimensions
- La r√©gression logistique mod√©lise pr√©cis√©ment ces fronti√®res lin√©aires
- Les arbres cr√©ent des fronti√®res "en escalier" moins optimales pour ce type de s√©paration

---

## üóÉÔ∏è PARTIE 5 ‚Äî MOD√âLISATION ET STOCKAGE NoSQL

### 5.1 Structure document MongoDB (iris_data)

```json
{
  "id": "IR001",
  "features": {
    "sepal_length": 5.1,
    "sepal_width": 3.5,
    "petal_length": 1.4,
    "petal_width": 0.2
  },
  "label": "Iris-setosa"
}
```

**Choix de conception** :
- **Sous-document `features`** : Regroupement logique des mesures morphologiques (sch√©ma flexible MongoDB)
- **`id` s√©quentiel** (IR000, IR001, ...) : Identifiant m√©tier lisible
- **`label`** : Esp√®ce de la fleur en clair
- **Insertion en masse** : `insert_many()` pour les 150 documents

### 5.2 Structure document MongoDB (iris_predictions)

```json
{
  "iris_id": "IR000",
  "original_label": "Iris-setosa",
  "predicted_index": 0.0,
  "confidence": "[0.9998, 0.0002, 2.69e-21]"
}
```

**Choix** : Stockage s√©par√© des pr√©dictions pour ne pas polluer les donn√©es brutes. Le champ `confidence` contient les probabilit√©s par classe.

### 5.3 Sch√©ma Cassandra (wide-column)

```sql
CREATE TABLE iris (
    id text,
    sepal_length float,
    sepal_width float,
    petal_length float,
    petal_width float,
    species text,
    PRIMARY KEY ((species), id)
);
```

**Partitionnement** : `PRIMARY KEY ((species), id)` ‚Üí les donn√©es sont **partitionn√©es par esp√®ce**. Toutes les fleurs de la m√™me esp√®ce sont sur le m√™me n≈ìud, ce qui optimise les requ√™tes de type `WHERE species = 'Iris-setosa'`.

### 5.4 Redis (Cache temps r√©el)

- **Fonction** : Cache des pr√©dictions du dashboard Streamlit
- **Structure cl√©** : `pred:{sepal_length}:{sepal_width}:{petal_length}:{petal_width}` ‚Üí la valeur est l'esp√®ce pr√©dite
- **TTL** : Pas de TTL (persistant)
- **Performance** : R√©ponse < 1ms (vs ~50ms pour un calcul ML)

---

## ‚ö° PARTIE 6 ‚Äî OPTIMISATION DES PERFORMANCES

### 6.1 Index MongoDB cr√©√©s

| Index | Type | Colonnes | Nom |
|---|---|---|---|
| _id_ | Par d√©faut | `_id` | (automatique) |
| idx_label | **Simple** | `label` | Index sur l'esp√®ce |
| idx_petal_dims | **Compos√©** | `features.petal_length` + `features.petal_width` | Index sur les features discriminantes |
| idx_sepal_length | Simple | `features.sepal_length` | Index sur sepal_length |

### 6.2 Benchmark Avant/Apr√®s Indexation (500 it√©rations par requ√™te)

| Requ√™te | SANS Index (ms) | AVEC Index (ms) | Gain | Throughput SANS | Throughput AVEC |
|---|---|---|---|---|---|
| Filter par esp√®ce (label) | 0.3296 | 0.2707 | **+17.9%** | 3 034 req/s | 3 695 req/s |
| Filter par petal dims | 0.2413 | 0.3302 | -36.8% | 4 144 req/s | 3 028 req/s |
| Filter par sepal_length | 0.2976 | 0.2930 | +1.5% | 3 360 req/s | 3 413 req/s |

**Analyse des r√©sultats** :
- Sur **150 documents**, l'impact de l'indexation est **mod√©r√©** car MongoDB peut scanner la collection enti√®re tr√®s rapidement (tout tient en RAM)
- Le gain de +17.9% sur le filtre par esp√®ce montre quand m√™me l'efficacit√© de l'index simple
- Sur un gros volume (>10 000 docs), les gains seraient **beaucoup plus importants** (√ó10 √† √ó100)
- Le cas de l'index compos√© (petal dims) montre un surco√ªt car la lecture de l'arbre B-tree est plus co√ªteuse que le scan lin√©aire sur un si petit volume

Le graphique comparatif est disponible dans : `output/benchmark/index_benchmark_comparison.png`

### 6.3 Profiling MongoDB

Activation du profiler MongoDB (Level 2 = toutes les op√©rations) pour valider l'utilisation des index :

| Requ√™te | Plan d'ex√©cution | Index utilis√© |
|---|---|---|
| `find({"label": "Iris-setosa"})` | **IXSCAN** | idx_label ‚úÖ |
| `find({"features.petal_length": {$gt: 1.5}, ...})` | **IXSCAN** | idx_petal_dims ‚úÖ |
| Aggregation `$group` par label | **COLLSCAN** | Aucun (normal pour une agr√©gation) |

**Conclusion** : Les index sont **bien utilis√©s** par MongoDB sur les requ√™tes de filtre. Les agr√©gations font un scan complet, ce qui est normal.

### 6.4 Benchmark multi-bases (ops/sec)

Comparaison des 3 bases NoSQL sur 1000 op√©rations :

Le graphique est disponible dans : `output/benchmark/benchmark_plot.png`

**R√©sultat attendu :**
- **Redis** : ~10x √† 100x plus rapide que MongoDB/Cassandra (in-memory)
- **MongoDB** : Bon compromis flexibilit√©/performance
- **Cassandra** : Plus lent sur de petits volumes (optimis√© pour le distribu√©)

‚Üí **Justification de l'architecture polyglotte** : chaque base NoSQL a son r√¥le optimal.

---

## üñ•Ô∏è PARTIE 7 ‚Äî PROTOTYPE INTERACTIF (Dashboard Streamlit)

### 7.1 Pages du dashboard

| Page | Fonctionnalit√© |
|---|---|
| **üìä Analyse Exploratoire (EDA)** | Distribution des esp√®ces (countplot), scatter plot interactif (axes configurables), statistiques globales |
| **üîÆ Pr√©diction & Cache Redis** | Sliders pour saisir les mesures, pr√©diction temps r√©el (Random Forest), cache Redis (HIT/MISS affich√©) |
| **üìà Performance & Big Data** | R√©sultats Spark MLlib (tableau highlight), benchmark BDD (graphique ops/sec) |

### 7.2 Int√©gration Redis d√©montr√©e

1. L'utilisateur r√®gle les 4 sliders (sepal_length, sepal_width, petal_length, petal_width)
2. Clic sur "Pr√©dire" ‚Üí le mod√®le Random Forest calcule (MISS CACHE)
3. Re-clic sans changer les valeurs ‚Üí Redis retourne le r√©sultat en <1ms (HIT CACHE)
4. Le message est affich√© en vert "‚ö° HIT CACHE REDIS" avec le r√©sultat

---

## üîó PARTIE 8 ‚Äî INT√âGRATION SPARK MLlib

### 8.1 Pipeline Spark

1. **Chargement** : Lecture depuis MongoDB ‚Üí DataFrame Spark (via MongoDB Spark Connector 10.3.0)
2. **Buffer Parquet** : Sauvegarde temporaire en Parquet pour contourner un bug de compatibilit√© connector
3. **Preprocessing** : StringIndexer (label ‚Üí labelIndex) + VectorAssembler (4 features ‚Üí features_vec)
4. **Split** : 80% train / 20% test (seed=42)
5. **Entra√Ænement** : 3 mod√®les (RF, DT, LR) avec √©valuation compl√®te
6. **Meilleur mod√®le** : R√©-entra√Æn√© sur 100% des donn√©es
7. **Sauvegarde MongoDB** : 150 pr√©dictions + probabilit√©s stock√©es dans `iris_predictions` via PyMongo

### 8.2 Contournement technique (√† mentionner)

Un bug de compatibilit√© entre Spark 3.5.1 et le MongoDB Spark Connector (NoSuchMethodError dans le `fit()`) a n√©cessit√© une **strat√©gie tampon Parquet** :
- Lecture MongoDB ‚Üí Parquet temporaire ‚Üí Relecture Parquet ‚Üí Training
- Les r√©sultats sont ensuite r√©inject√©s dans MongoDB via PyMongo (plus fiable que le connector pour l'√©criture)

---

## üìã R√âPONSES AUX QUESTIONS DU BRIEF

### Questions Partie 1 ‚Äî Analyse descriptive

**Q1 : Quelles esp√®ces semblent surrepr√©sent√©es ?**
‚Üí Aucune. Le dataset est parfaitement √©quilibr√© avec exactement 50 observations par esp√®ce.

**Q2 : Existe-t-il des diff√©rences marqu√©es de taille entre les esp√®ces ?**
‚Üí Oui, tr√®s marqu√©es sur les p√©tales. Setosa a des p√©tales 3.8√ó plus courts et 8.3√ó plus √©troits que Virginica. Les s√©pales varient moins (√ó1.3 en longueur).

**Q3 : Les p√©tales ou les s√©pales semblent-ils plus discriminants ?**
‚Üí Les **p√©tales** sont nettement plus discriminants. L'√©cart inter-esp√®ces est beaucoup plus grand sur petal_length (1.46‚Üí5.55) et petal_width (0.24‚Üí2.03) que sur les s√©pales.

### Questions Partie 2 ‚Äî Visualisation

**Q1 : Quelles variables semblent fortement corr√©l√©es ?**
‚Üí petal_length et petal_width (r=0.963, corr√©lation quasi-parfaite). Aussi sepal_length avec petal_length (r=0.872) et petal_width (r=0.818).

**Q2 : Existe-t-il des biais visuels ?**
‚Üí Le principal biais est l'effet de Simpson : la corr√©lation globale sepal_width ‚Üî petal_length est n√©gative (-0.42), mais au sein de chaque esp√®ce, la relation peut √™tre positive. Il faut toujours analyser les corr√©lations par esp√®ce.

**Q3 : Quelles observations permettent de mieux distinguer les esp√®ces ?**
‚Üí Les scatter plots petal_length vs petal_width montrent la meilleure s√©paration. Setosa forme un cluster isol√© en bas √† gauche. Versicolor et Virginica sont s√©parables mais avec un l√©ger chevauchement.

### Questions Partie 3 ‚Äî R√©gression

**Q1 : Quels param√®tres influencent le plus la longueur des p√©tales ?**
‚Üí petal_width (coefficient 1.447, t=21.4) est le facteur le plus influent, suivi de sepal_length (0.729) et sepal_width (-0.646, relation n√©gative).

**Q2 : Le mod√®le multiple am√©liore-t-il la pr√©diction ?**
‚Üí Oui, consid√©rablement. R¬≤ passe de 0.760 (simple) √† 0.968 (multiple), soit +20.8 points. L'AIC passe de 385 √† 87.

**Q3 : Les hypoth√®ses sont-elles respect√©es ?**
‚Üí Oui, toutes valid√©es : lin√©arit√© (R¬≤ √©lev√©), normalit√© des r√©sidus (Prob(JB)=0.303), homosc√©dasticit√© (dispersion uniforme des r√©sidus), absence d'autocorr√©lation (DW=1.783).

### Questions Partie 4 ‚Äî Classification

**Q1 : Quelles esp√®ces sont les plus difficiles √† pr√©dire ?**
‚Üí Versicolor et Virginica sont les plus confondues entre elles (erreurs crois√©es dans RF et DT). Setosa est toujours class√©e parfaitement gr√¢ce √† ses p√©tales tr√®s distinctifs.

**Q2 : Quelles variables sont les plus discriminantes pour la classification ?**
‚Üí petal_length et petal_width. Elles permettent la meilleure s√©paration lin√©aire entre les 3 esp√®ces.

**Q3 : Quels indicateurs statistiques sont les plus pertinents ?**
‚Üí L'Accuracy (mesure globale), le F1-score (√©quilibre precision/recall, important pour les classes d√©s√©quilibr√©es), et la matrice de confusion (identification des confusions entre esp√®ces).

---

## üìÇ LISTE COMPL√àTE DES FICHIERS DE SORTIE

### Graphiques (pour insertion dans le Word)

| Fichier | Description |
|---|---|
| `output/plots/pairplot.png` | Pairplot complet par esp√®ce |
| `output/plots/correlation_matrix.png` | Matrice de corr√©lation (heatmap) |
| `output/plots/boxplots.png` | Boxplots de toutes les variables |
| `output/plots/violin_sepal_length.png` | Violinplot sepal_length par esp√®ce |
| `output/plots/violin_sepal_width.png` | Violinplot sepal_width par esp√®ce |
| `output/plots/violin_petal_length.png` | Violinplot petal_length par esp√®ce |
| `output/plots/violin_petal_width.png` | Violinplot petal_width par esp√®ce |
| `output/regression/regression_simple_plot.png` | Droite de r√©gression simple |
| `output/regression/residuals_plot.png` | R√©sidus vs pr√©dictions (homosc√©dasticit√©) |
| `output/regression/residuals_qqplot.png` | QQ-plot (normalit√© r√©sidus) |
| `output/benchmark/benchmark_plot.png` | Benchmark multi-bases (ops/sec) |
| `output/benchmark/index_benchmark_comparison.png` | Benchmark avant/apr√®s indexation |

### Donn√©es CSV

| Fichier | Description |
|---|---|
| `output/eda_stats.txt` | Statistiques descriptives compl√®tes |
| `output/classification/metrics.csv` | Accuracy, Precision, Recall, F1 par mod√®le |
| `output/classification/confusion_matrix_random_forest.csv` | Matrice de confusion RF |
| `output/classification/confusion_matrix_decision_tree.csv` | Matrice de confusion DT |
| `output/classification/confusion_matrix_logistic_regression.csv` | Matrice de confusion LR |
| `output/classification/classification_report_random_forest.csv` | Rapport d√©taill√© RF |
| `output/classification/classification_report_decision_tree.csv` | Rapport d√©taill√© DT |
| `output/classification/classification_report_logistic_regression.csv` | Rapport d√©taill√© LR |
| `output/regression/regression_simple_summary.txt` | R√©sum√© OLS simple |
| `output/regression/regression_multiple_summary.txt` | R√©sum√© OLS multiple |
| `output/benchmark/index_benchmark.csv` | Benchmark indexation (avant/apr√®s) |

### Scripts source

| Script | R√¥le |
|---|---|
| `src/data_loader.py` | Chargement iris.data ‚Üí MongoDB + Cassandra + Redis |
| `src/eda_analysis.py` | Analyse exploratoire (stats descriptives, graphiques) |
| `src/regression_analysis.py` | R√©gressions simple et multiple (statsmodels OLS) |
| `src/classifier.py` | Classification Spark MLlib (RF, DT, LR) + matrices de confusion |
| `src/create_indexes.py` | Cr√©ation des index MongoDB |
| `src/profiling_mongo.py` | Profiling MongoDB (validation des index) |
| `src/benchmark_indexes.py` | Benchmark avant/apr√®s indexation |
| `src/benchmark_suite.py` | Benchmark multi-bases (MongoDB vs Cassandra vs Redis) |
| `src/app.py` | Dashboard Streamlit interactif |

---

## üìå INSTRUCTIONS POUR CLAUDE

Ce document contient TOUT ce dont tu as besoin pour r√©diger un rapport Word complet.

**Structure sugg√©r√©e pour le Word :**
1. Page de garde
2. Introduction (contexte, probl√©matique)
3. Partie 1 : Analyse Exploratoire (utiliser les stats et les graphiques)
4. Partie 2 : Visualisation (ins√©rer les graphiques du dossier output/plots/)
5. Partie 3 : R√©gression (copier les r√©sultats OLS, ins√©rer les graphiques r√©sidus)
6. Partie 4 : Classification supervis√©e (tableaux de m√©triques + matrices de confusion)
7. Partie 5 : Architecture NoSQL (structures MongoDB, Cassandra, Redis)
8. Partie 6 : Optimisation (index, profiling, benchmark avant/apr√®s)
9. Partie 7 : Int√©gration Spark MLlib (pipeline, r√©sultats)
10. Partie 8 : Prototype interactif (dashboard Streamlit)
11. Conclusion

**Les images √† ins√©rer** sont dans le dossier `output/` du projet.
**Les donn√©es chiffr√©es** sont toutes dans ce document.
**Les r√©ponses aux questions** sont dans la section "R√©ponses aux Questions du Brief".
