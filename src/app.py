import streamlit as st
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from pymongo import MongoClient
import redis
from sklearn.ensemble import RandomForestClassifier
import os

# Configuration de la page
st.set_page_config(page_title="Iris Classification - TPML", layout="wide", page_icon="üå∫")

# --- Fonctions de chargement (Caches) ---

@st.cache_resource
def init_connections():
    """Initialise les connexions aux bases de donn√©es."""
    try:
        mongo_client = MongoClient("mongodb://localhost:27017/")
        mongo_client.server_info() # Test connexion
        db = mongo_client["tpml_iris"]
        
        redis_client = redis.Redis(host='localhost', port=6379, decode_responses=True)
        redis_client.ping() # Test connexion
        
        return db, redis_client
    except Exception as e:
        st.error(f"Erreur de connexion BDD: {e}")
        return None, None

@st.cache_data
def load_data():
    """Charge les donn√©es depuis MongoDB."""
    db, _ = init_connections()
    if db is not None:
        collection = db["iris_data"]
        data = list(collection.find())
        if not data:
            return pd.DataFrame()
        
        normalized_data = []
        for doc in data:
            item = doc.get('features', {})
            item['species'] = doc.get('label')
            item['id'] = doc.get('id')
            normalized_data.append(item)
            
        return pd.DataFrame(normalized_data)
    return pd.DataFrame()

@st.cache_resource
def train_demo_model(df):
    """Entra√Æne un mod√®le Random Forest pour la d√©mo interactive."""
    if df.empty:
        return None
    X = df[['sepal_length', 'sepal_width', 'petal_length', 'petal_width']]
    y = df['species']
    clf = RandomForestClassifier(n_estimators=100, random_state=42)
    clf.fit(X, y)
    return clf

@st.cache_resource
def load_image_model():
    """Charge le pipeline de classification d'images (ViT)."""
    try:
        from transformers import pipeline
        return pipeline("image-classification", model="google/vit-base-patch16-224")
    except Exception as e:
        return None

# --- Chargement initial des ressources ---
db, redis_client = init_connections()
df = load_data()
model = train_demo_model(df) if not df.empty else None

# --- Sidebar & Navigation ---
st.sidebar.title("üå∫ Navigation")
st.sidebar.markdown("Explorez les diff√©rentes facettes du projet.")

page = st.sidebar.radio(
    "Aller vers :",
    [
        "1. üìä Analyse Exploratoire (EDA)",
        "2. üîÆ Pr√©diction & Cache Redis", 
        "3. üìà Performance & Big Data",
        "4. üì∑ Vision par Ordinateur"
    ]
)

st.sidebar.markdown("---")
st.sidebar.header("Options G√©n√©rales")
if st.sidebar.button("üîÑ Recharger les donn√©es"):
    load_data.clear()
    st.rerun()

st.sidebar.info(
    "**Projet TPML**\n\n"
    "Architecture Polyglotte :\n"
    "- **MongoDB** : Stockage Donn√©es\n"
    "- **Cassandra** : Historique\n"
    "- **Redis** : Cache Temps R√©el\n"
    "- **Spark** : Entra√Ænement Distribu√©"
)

# --- Contenu Principal ---

st.title("üå∫ Classification des Iris - Dashboard interactif")

if page == "1. üìä Analyse Exploratoire (EDA)":
    st.header("üìä Analyse Exploratoire des Donn√©es (EDA)")
    
    with st.expander("üìò **Comprendre cette section (Aide)**", expanded=True):
        st.markdown("""
        **√Ä quoi √ßa sert ?**
        Cette page permet de visualiser les donn√©es brutes stock√©es dans **MongoDB**. C'est la premi√®re √©tape de tout projet de Data Science : comprendre la donn√©e.
        
        **Ce que vous pouvez faire ici :**
        1. **V√©rifier l'√©quilibre des classes** : Le graphique de gauche doit montrer un nombre √©gal de fleurs pour chaque esp√®ce.
        2. **Analyser les corr√©lations** : Le scatter plot interactif √† droite permet de voir quelles mesures (p√©tales/s√©pales) s√©parent le mieux les esp√®ces.
        3. **Consulter les statistiques** : Le tableau en bas donne les moyennes et √©carts-types.
        """)
        
    if df.empty:
        st.warning("Aucune donn√©e trouv√©e.")
    else:
        col1, col2 = st.columns(2)
        with col1:
            st.subheader("Distribution des Esp√®ces")
            st.caption("On v√©rifie ici que le dataset est bien √©quilibr√©.")
            fig_count = plt.figure(figsize=(6, 4))
            sns.countplot(data=df, x='species', palette="viridis")
            st.pyplot(fig_count)
            
        with col2:
            st.subheader("Nuage de Points Interactif")
            st.caption("Jouez avec les axes pour voir comment les esp√®ces se s√©parent g√©om√©triquement.")
            x_axis = st.selectbox("Choisir l'Axe X", df.columns[:-2], index=2)
            y_axis = st.selectbox("Choisir l'Axe Y", df.columns[:-2], index=3)
            
            fig_scatter = plt.figure(figsize=(6, 4))
            sns.scatterplot(data=df, x=x_axis, y=y_axis, hue='species', palette="viridis")
            st.pyplot(fig_scatter)
            
        st.subheader("Statistiques Globales")
        st.dataframe(df.describe())

elif page == "2. üîÆ Pr√©diction & Cache Redis":
    st.header("üîÆ Pr√©diction Temps R√©el & Cache Redis")
    
    with st.expander("üìò **Comprendre cette section (Aide)**", expanded=True):
        st.markdown("""
        **√Ä quoi √ßa sert ?**
        Cette section d√©montre la puissance de l'architecture **Hybride ML + Redis**.
        
        **Le D√©fi :** Les mod√®les de ML peuvent √™tre lents √† r√©pondre si beaucoup d'utilisateurs les sollicitent.
        **La Solution :** Utiliser **Redis** comme m√©moire cache ultra-rapide.
        
        **Testez-le vous-m√™me !**
        1. R√©glez les sliders pour d√©finir une fleur.
        2. Cliquez sur **Pr√©dire**. Le mod√®le calcule (c'est plus long).
        3. **Re-cliquez** sans changer les valeurs. Le r√©sultat s'affiche instantan√©ment (< 1ms) gr√¢ce √† Redis !
        """)
    
    col_input, col_result = st.columns([1, 1])
    
    with col_input:
        st.subheader("Param√®tres de la Fleur")
        sl = st.slider("Longueur S√©pale (cm)", 4.0, 8.0, 5.8)
        sw = st.slider("Largeur S√©pale (cm)", 2.0, 5.0, 3.0)
        pl = st.slider("Longueur P√©tale (cm)", 1.0, 7.0, 4.0)
        pw = st.slider("Largeur P√©tale (cm)", 0.1, 3.0, 1.2)
        
        predict_btn = st.button("üöÄ Lancer la Pr√©diction", type="primary")
        
    with col_result:
        st.subheader("R√©sultat de l'IA")
        if predict_btn and model:
            # Cl√© de cache unique bas√©e sur les inputs
            cache_key = f"pred:{sl}:{sw}:{pl}:{pw}"
            
            # 1. V√©rification dans le Cache Redis
            cached_res = redis_client.get(cache_key)
            
            if cached_res:
                st.success(f"üåø Esp√®ce Identifi√©e : **{cached_res}**")
                st.info("‚ö° **HIT CACHE REDIS** : R√©sultat r√©cup√©r√© en m√©moire (< 1ms).")
                st.balloons()
            else:
                # 2. Calcul par le Mod√®le (si pas en cache)
                prediction = model.predict([[sl, sw, pl, pw]])[0]
                st.success(f"üåø Esp√®ce Identifi√©e : **{prediction}**")
                st.warning("üß† **MISS CACHE** : Calcul effectu√© par le mod√®le Random Forest.")
                
                # 3. Stockage dans Redis pour la prochaine fois
                redis_client.set(cache_key, prediction)

elif page == "3. üìà Performance & Big Data":
    st.header("üìà Performances Syst√®me & Mod√®les Distribu√©s")
    
    with st.expander("üìò **Comprendre cette section (Aide)**", expanded=True):
        st.markdown("""
        **√Ä quoi √ßa sert ?**
        Ici, on quitte le temps r√©el pour analyser les travaux de fond (Batch Processing).
        
        **Ce que l'on voit :**
        1. **R√©sultats Spark MLlib** : La pr√©cision des mod√®les entra√Æn√©s sur tout le Big Data. Cela prouve la qualit√© scientifique de l'approche.
        2. **Benchmark BDD** : Une comparaison objective entre MongoDB, Cassandra et Redis. C'est la justification technique de nos choix d'architecture.
        """)

    st.subheader("1. R√©sultats de la Classification Distribu√©e (Spark)")
    metrics_path = "output/classification/metrics.csv"
    if os.path.exists(metrics_path):
        metrics_df = pd.read_csv(metrics_path)
        st.dataframe(metrics_df.style.highlight_max(axis=0, color='lightgreen'))
        
        best_model = metrics_df.loc[metrics_df['Accuracy'].idxmax()]
        st.markdown(f"üèÜ **Champion :** Le mod√®le **{best_model['Model']}** est le plus performant avec une pr√©cision de **{best_model['Accuracy']:.2%}**.")
    else:
        st.error("Les m√©triques n'ont pas encore √©t√© g√©n√©r√©es. Lancez `classifier.py`.")
        
    st.markdown("---")
    
    st.subheader("2. Benchmark de Performance (Ops/sec)")
    bench_img = "output/benchmark/benchmark_plot.png"
    if os.path.exists(bench_img):
        st.image(bench_img, caption="Comparaison Lecture/√âcriture : Redis √©crase la concurrence !", use_column_width=True)
        st.info("üí° **Analyse** : Redis est ~10x √† 100x plus rapide que les autres bases NoSQL pour les op√©rations simples, ce qui valide son utilisation en cache.")
    else:
        st.warning("Le graphique de benchmark n'est pas disponible. Lancez `benchmark_suite.py`.")

elif page == "4. üì∑ Vision par Ordinateur":
    st.header("üì∑ Reconnaissance d'Images (Vision par Ordinateur)")
    
    with st.expander("üìò **Comprendre cette section (Aide)**", expanded=True):
        st.markdown("""
        **√Ä quoi √ßa sert ?**
        C'est une fonctionnalit√© bonus utilisant le **Deep Learning** moderne (Transformers).
        Contrairement aux onglets pr√©c√©dents qui utilisaient des mesures (chiffres), ici l'IA "regarde" une photo.
        
        **Technologie :** Vision Transformer (ViT) de Google. C'est un r√©seau de neurones qui d√©coupe l'image en morceaux pour l'analyser.
        
        **Essayez !** Importez une photo de fleur (t√©l√©charg√©e sur Google Images) et voyez si l'IA la reconna√Æt.
        """)
        
    uploaded_file = st.file_uploader("üì• D√©posez une image de fleur ici (JPG, PNG)...", type=["jpg", "jpeg", "png"])
    
    if uploaded_file is not None:
        from PIL import Image
        image = Image.open(uploaded_file)
        
        col_img, col_an = st.columns(2)
        with col_img:
            st.image(image, caption='Votre image', use_column_width=True)
        
        with col_an:
            st.write("ü§ñ **L'IA analyse l'image...**")
            with st.spinner('Chargement du mod√®le Vision Transformer...'):
                classifier = load_image_model()
                if classifier:
                    predictions = classifier(image)
                    st.success("Analyse termin√©e !")
                    
                    # Top pr√©diction
                    top_p = predictions[0]
                    confidence = top_p['score']
                    label = top_p['label']
                    
                    if confidence > 0.7:
                        st.balloons()
                        st.markdown(f"### üå∏ R√©sultat : **{label}**")
                        st.markdown(f"**Confiance : {confidence:.1%}**")
                    else:
                        st.markdown(f"### ü§î R√©sultat incertain : **{label}**")
                        st.caption(f"Confiance faible ({confidence:.1%}). L'image est peut-√™tre floue ou ce n'est pas une fleur connue.")
                    
                    # Tableau d√©taill√©
                    st.markdown("#### D√©tails des probabilit√©s :")
                    res_data = [{"Fleur": p['label'], "Probabilit√©": p['score']} for p in predictions]
                    st.dataframe(pd.DataFrame(res_data).style.format({"Probabilit√©": "{:.2%}"}))
                else:
                    st.error("Impossible de charger le mod√®le de vision. V√©rifiez votre connexion internet pour t√©l√©charger les poids du mod√®le.")
